{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning On MNIST\n",
    "In this notebook you will be given an introduction to MNIST Database.\n",
    "https://en.wikipedia.org/wiki/MNIST_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with loading the data.  \n",
    "Download the training and testing database from: http://yann.lecun.com/exdb/mnist/  \n",
    "Extract and make csv files using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def convertMnistToCsv(x,y,out_name,size):\n",
    "    #Creating new file\n",
    "    new_file = open(out_name, \"w\") \n",
    "    x.read(16)\n",
    "    y.read(8)\n",
    "    images = []\n",
    "\n",
    "    #Adding the first line in the csv file (the columns)\n",
    "    columns = \"Label\"       \n",
    "    for i in range(28*28):\n",
    "        columns += \",P\"+str(i)\n",
    "    new_file.write(columns+\"\\n\")\n",
    "\n",
    "    #Making the data matrix\n",
    "    for i in range(size):       \n",
    "        img = [ord(y.read(1))]\n",
    "        for j in range(28*28):\n",
    "            img.append(ord(x.read(1)))\n",
    "        images.append(img)\n",
    "\n",
    "    #Combining each row and writing to the new file in csv format\n",
    "    for img in images:\n",
    "        new_file.write(\",\".join(str(p) for p in img)+\"\\n\")\n",
    "\n",
    "    x.close()\n",
    "    y.close()\n",
    "    new_file.close()\n",
    "\n",
    "Xtrain = gzip.open(\"train-images-idx3-ubyte.gz\",'r')\n",
    "Ytrain = gzip.open(\"train-labels-idx1-ubyte.gz\",'r')\n",
    "Xtest = gzip.open(\"t10k-images-idx3-ubyte.gz\",'r')\n",
    "Ytest = gzip.open(\"t10k-labels-idx1-ubyte.gz\",'r')\n",
    "convertMnistToCsv(Xtrain, Ytrain, \"mnist_train.csv\", 60000)\n",
    "convertMnistToCsv(Xtest, Ytest,\"mnist_test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output files (A notepad for large data or Pandas library),\"mnist_train.csv\" and \"mnist_test.csv\", and observing the first row (Columns row) shows the format of the files: Label,P0,P1,...P783.  \n",
    "The first column is the label of the image, and \"P'i'\" is the pixel located in 0<=i<=783, where 0<=P'i'<=255  \n",
    "\n",
    "Split the data into two datasets(Xtrain,Xtest) and two label sets(Ytrain,Ytest) corresponding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv(\"mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"mnist_test.csv\")\n",
    "\n",
    "Xtrain = train_data.iloc[:,1:]\n",
    "Ytrain = train_data.iloc[:,:1]\n",
    "Ytrain = Ytrain.values.ravel()\n",
    "\n",
    "Xtest = test_data.iloc[:,1:]\n",
    "Ytest = test_data.iloc[:,:1]\n",
    "Ytest = Ytest.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make two additional datasets to test the difference when modifying the data:  \n",
    "&middot; Categorical - combining interval of number to specific label.  \n",
    "&middot; Normalized - all the values become between 0 to 1, and unnecessary columns deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataset by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catXtrain = pd.DataFrame()\n",
    "catXtest = pd.DataFrame()\n",
    "for col in Xtrain.columns:\n",
    "    catXtrain[col+'_cat'] = pd.cut(Xtrain[col],bins=[-np.inf, 50, np.inf],labels=[0,1])\n",
    "    catXtest[col+'_cat'] = pd.cut(Xtest[col],bins=[-np.inf, 50, np.inf],labels=[0,1])\n",
    "    \n",
    "catXtrain = catXtrain.astype(np.int64)\n",
    "catXtest = catXtest.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataset with normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normXtrain = Xtrain / 255\n",
    "normXtest = Xtest / 255\n",
    "for column in normXtrain:\n",
    "    if normXtrain[column].mean() == 0. and normXtest[column].mean() == 0.:\n",
    "        normXtrain = normXtrain.drop([column],axis=1)\n",
    "        normXtest = normXtest.drop([column],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make correlation matrix for the category dataset.  \n",
    "As you can expect, there is a high correlation between a pixel and its sourounding pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = catXtrain.corr()\n",
    "corr_matrix[\"P300_cat\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe statistical stats about the normalized dataset.  \n",
    "As you can expect, max is always greather than 1 and the mean is always greather then 0.  \n",
    "Also we can assume that 65 = 784 - 719 columns were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normXtrain.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build three SVM models for each dataset (Xtrain, catXtrain, normXtrain).  \n",
    "Evaluate the models using cross validation for under/overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Original dataset\n",
    "svm_model1 = svm.SVC(kernel='linear',C=1,decision_function_shape='ovo').fit(Xtrain.iloc[:1000],Ytrain[:1000])\n",
    "scores1 = cross_val_score(svm_model1,Xtrain.iloc[:1000],Ytrain[:1000],cv=5)\n",
    "\n",
    "#Categorical dataset\n",
    "svm_model2 = svm.SVC(kernel='linear',C=1,decision_function_shape='ovo').fit(catXtrain.iloc[:1000],Ytrain[:1000])\n",
    "scores2 = cross_val_score(svm_model2,catXtrain.iloc[:1000],Ytrain[:1000],cv=5)\n",
    "\n",
    "#Normalized dataset\n",
    "svm_model3 = svm.SVC(kernel='rbf',C=1,decision_function_shape='ovo').fit(normXtrain.iloc[:1000],Ytrain[:1000])\n",
    "scores3 = cross_val_score(svm_model3,normXtrain.iloc[:1000],Ytrain[:1000],cv=5)\n",
    "\n",
    "print(\"Original Xtrain:\")\n",
    "print(\"Cross validation Score:\",scores1.mean(),\"+/-\",scores1.std() * 2)\n",
    "print(\"Test sample Score:\",svm_model1.score(Xtest.iloc[:2000],Ytest[:2000]),\"\\n\")\n",
    "\n",
    "print(\"Category Xtrain:\")\n",
    "print(\"Cross validation Score:\",scores2.mean(),\"+/-\",scores2.std() * 2)\n",
    "print(\"Test sample Scoree:\",svm_model2.score(catXtest.iloc[:2000],Ytest[:2000]),\"\\n\")\n",
    "\n",
    "print(\"Normalized Xtrain:\")\n",
    "print(\"Cross validation Score:\",scores3.mean(),\"+/-\",scores3.std() * 2)\n",
    "print(\"Test sample Score\",svm_model3.score(normXtest.iloc[:2000],Ytest[:2000]),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore different metrics to evaluate the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&middot; Use confusion matrix to find labels with high number of false-positive or false-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "plot_confusion_matrix(svm_model1,Xtest.iloc[:2000],Ytest[:2000],labels=labels)\n",
    "confusion_matrix(Ytest[:2000],svm_model1.predict(Xtest.iloc[:2000]),labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&middot; Use Precision and Recall to improve f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "y_test_pred = svm_model1.predict(Xtest.iloc[:2000])\n",
    "pre_score = precision_score(Ytest[:2000], y_test_pred,average=None)\n",
    "rc_score = recall_score(Ytest[:2000], y_test_pred,average=None)\n",
    "comb_score = f1_score(Ytest[:2000],y_test_pred,average=None)\n",
    "\n",
    "x = np.arange(len(labels)) \n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, pre_score, width, label='Precision')\n",
    "rects2 = ax.bar(x + width/2, rc_score, width, label='Recall')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Metrics Compare')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
